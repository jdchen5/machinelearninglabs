{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d377b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3419b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"some_image.pgm\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74202bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an2i',\n",
       " 'at33',\n",
       " 'boland',\n",
       " 'bpm',\n",
       " 'ch4f',\n",
       " 'cheyer',\n",
       " 'choon',\n",
       " 'danieln',\n",
       " 'glickman',\n",
       " 'karyadi',\n",
       " 'kawamura',\n",
       " 'kk49',\n",
       " 'megak',\n",
       " 'mitchell',\n",
       " 'night',\n",
       " 'phoebe',\n",
       " 'saavik',\n",
       " 'steffi',\n",
       " 'sz24',\n",
       " 'tammo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def img_loader(filename):\n",
    "    return cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "data = ImageFolder(root='./faces/', loader=img_loader, transform=transforms)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cfee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import nn\n",
    "\n",
    "# Assuming num_expressions is defined based on your dataset\n",
    "num_expressions = 5  # Update this based on your dataset's number of expressions\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5) # Input channels, Output channels, Kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) # Adjust input size based on the output of conv2\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Task T1: Binary classification (Mitchell or not) (binary)\n",
    "        self.fc3_mitchell = nn.Linear(84, 2)  \n",
    "        # Task T2: Facial expression classification\n",
    "        self.fc3_expression = nn.Linear(84, num_expressions)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # Pooling size\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # Pooling size\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out_mitchell = self.fc3_mitchell(x)\n",
    "        out_expression = self.fc3_expression(x)\n",
    "        return out_mitchell, out_expression\n",
    " \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086b69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in dataset: 1872\n",
      "Image 0 - Shape: torch.Size([1, 32, 32]), Label: 0\n",
      "Image 1 - Shape: torch.Size([1, 32, 32]), Label: 0\n",
      "Image 2 - Shape: torch.Size([1, 32, 32]), Label: 0\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Example transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Assuming your custom img_loader function and ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root='./faces', transform=transform)\n",
    "\n",
    "print(f\"Total images in dataset: {len(dataset)}\")\n",
    "\n",
    "# Optionally, check a few sample images\n",
    "for i in range(3):\n",
    "    img, label = dataset[i]\n",
    "    print(f\"Image {i} - Shape: {img.size()}, Label: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083e8971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n",
      "Shape of a batch of images: torch.Size([64, 1, 32, 32])\n",
      "Shape of a batch of labels: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check the first batch\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(f\"Batch size: {len(images)}\")\n",
    "print(f\"Shape of a batch of images: {images.shape}\")\n",
    "print(f\"Shape of a batch of labels: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2470e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = Net().to(device)\n",
    "# Your data and model are now explicitly set to use the CPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34abb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.get_backend())\n",
    "# You can try setting a different backend like this, for example:\n",
    "# plt.switch_backend('TkAgg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a100ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for img in images[:4]:\n",
    "    print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246289cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_img = images[0] / 2 + 0.5  # Unnormalize a single image\n",
    "plt.imshow(single_img.numpy().squeeze(), cmap='gray')  # Assuming the image is grayscale\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacea291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def imshow(img):\n",
    "    # Unnormalize\n",
    "    img = img / 2 + 0.5     # This is to reverse the normalization\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# Print labels for the displayed images\n",
    "print('Labels: ', ' '.join(f'{labels[j].item()}' for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a21156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # tqdm is a library for making loops show a smart progress meter\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}\")):\n",
    "        data, target = data.to(device), [t.to(device) for t in target]\n",
    "        optimizer.zero_grad()\n",
    "        output_mitchell, output_expression = model(data)\n",
    "        loss_mitchell = F.cross_entropy(output_mitchell, target[0])  # Assuming target[0] is for Mitchell\n",
    "        loss_expression = F.cross_entropy(output_expression, target[1])  # Assuming target[1] is for expression\n",
    "        loss = loss_mitchell + loss_expression\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Log training status here\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_mitchell = 0\n",
    "    correct_expression = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), [t.to(device) for t in target]\n",
    "            output_mitchell, output_expression = model(data)\n",
    "            # Calculate test loss and accuracy here\n",
    "\n",
    "    # Log testing status here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc9e92a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (64) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 32\u001b[0m\n\u001b[0;32m     27\u001b[0m         test(model, device, test_loader)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# When running as a script, pass the actual command line arguments\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 26\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     test(model, device, test_loader)\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      6\u001b[0m output_mitchell, output_expression \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m----> 7\u001b[0m loss_mitchell \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_mitchell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming target[0] is for Mitchell\u001b[39;00m\n\u001b[0;32m      8\u001b[0m loss_expression \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output_expression, target[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Assuming target[1] is for expression\u001b[39;00m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_mitchell \u001b[38;5;241m+\u001b[39m loss_expression\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Define default argument values\n",
    "    data_dir = './faces'\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    no_cuda = False\n",
    "\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # Load your data and split here\n",
    "    dataset = ImageFolder(root=data_dir, loader=img_loader, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "       \n",
    "if __name__ == '__main__':\n",
    "    # When running as a script, pass the actual command line arguments\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45d98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b19120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
