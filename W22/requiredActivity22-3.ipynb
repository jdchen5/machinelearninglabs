{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdchen5/machinelearninglabs/blob/main/W22/requiredActivity22-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUWKYGeuqrNP",
        "outputId": "20d5f12b-8141-47f8-b89e-b08f44db3e89"
      },
      "id": "nUWKYGeuqrNP",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "26d377b5",
      "metadata": {
        "id": "26d377b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from __future__ import print_function\n",
        "from torch.utils.data import DataLoader, random_split, Dataset, Subset\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3419b75b",
      "metadata": {
        "id": "3419b75b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "img = cv2.imread(\"some_image.pgm\", cv2.IMREAD_COLOR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "e74202bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e74202bf",
        "outputId": "72f0eaf0-2ba6-40ab-aafd-10457ab88526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['an2i',\n",
              " 'at33',\n",
              " 'boland',\n",
              " 'bpm',\n",
              " 'ch4f',\n",
              " 'cheyer',\n",
              " 'choon',\n",
              " 'danieln',\n",
              " 'glickman',\n",
              " 'karyadi',\n",
              " 'kawamura',\n",
              " 'kk49',\n",
              " 'megak',\n",
              " 'mitchell',\n",
              " 'night',\n",
              " 'phoebe',\n",
              " 'saavik',\n",
              " 'steffi',\n",
              " 'sz24',\n",
              " 'tammo']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "# Custom loader using OpenCV\n",
        "def img_loader(filename):\n",
        "    return cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "data = ImageFolder(root='/content/gdrive/My Drive/Pythoncode/W22/faces_4/', loader=img_loader, transform=transforms)\n",
        "data.classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Dictionary to hold expression counts for each class\n",
        "class_expressions = collections.defaultdict(lambda: collections.defaultdict(int))\n",
        "\n",
        "# Loop over all samples in the dataset\n",
        "for image_path, class_index in data.samples:\n",
        "    class_name = data.classes[class_index]\n",
        "    filename = os.path.basename(image_path)\n",
        "    # Split the filename and extract the expression\n",
        "    parts = filename.split('_')\n",
        "    if len(parts) >= 3:  # Check that there are enough parts to extract expression\n",
        "        # Concatenate the parts to form the expression string\n",
        "        expression = parts[1] + \"_\" + parts[2]  # The third part is assumed to be the expression\n",
        "        class_expressions[class_name][expression] += 1\n",
        "\n",
        "# Now 'class_expressions' contains the counts of each unique expression for each class\n",
        "for class_name, expressions in class_expressions.items():\n",
        "    print(f\"Class '{class_name}' expressions and counts:\")\n",
        "    for expression, count in expressions.items():\n",
        "        print(f\"{expression}: {count}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "elCGCkH0wczE",
        "outputId": "1c977753-1faa-4324-9497-3e7bfb1310b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "elCGCkH0wczE",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 'an2i' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'at33' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'boland' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'bpm' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'ch4f' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'cheyer' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'choon' expressions and counts:\n",
            "left_angry: 1\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'danieln' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 1\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'glickman' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 1\n",
            "straight_angry: 1\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'karyadi' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 1\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'kawamura' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 1\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'kk49' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'megak' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 1\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 1\n",
            "\n",
            "Class 'mitchell' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 1\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 1\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 1\n",
            "up_neutral: 1\n",
            "up_sad: 2\n",
            "\n",
            "Class 'night' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'phoebe' expressions and counts:\n",
            "left_angry: 1\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'saavik' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'steffi' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'sz24' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 1\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 2\n",
            "right_neutral: 2\n",
            "right_sad: 2\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n",
            "Class 'tammo' expressions and counts:\n",
            "left_angry: 2\n",
            "left_happy: 2\n",
            "left_neutral: 2\n",
            "left_sad: 2\n",
            "right_angry: 2\n",
            "right_happy: 1\n",
            "right_neutral: 2\n",
            "right_sad: 1\n",
            "straight_angry: 2\n",
            "straight_happy: 2\n",
            "straight_neutral: 2\n",
            "straight_sad: 2\n",
            "up_angry: 2\n",
            "up_happy: 2\n",
            "up_neutral: 2\n",
            "up_sad: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKvtPxPaC39g"
      },
      "id": "lKvtPxPaC39g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "47cfee25",
      "metadata": {
        "id": "47cfee25"
      },
      "outputs": [],
      "source": [
        "# LeNet-5 architecture adapted for face classification\n",
        "\n",
        "# the Net class to handle a single task at a time\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=4):  # Adjusted for a default of 4 classes\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)  # Adjusted based on pooling and padding\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 8 * 8)  # Adjusted based on pooling and padding\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MitchellNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MitchellNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        # Calculate the correct number of flattened features after the last pooling layer\n",
        "        # Here, we assume the size of the feature map after the convolutions and pooling is 5x5\n",
        "        # This number (16 * 5 * 5) must match the number of input features of self.fc1\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 4)  # Adjusted for 4 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #print(f\"MitchellNet Input batch size: {x.size(0)}\")  # Should always be 64 based on your DataLoader\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)  # Make sure this matches the output of conv2 layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "       # print(f\"Input batch size: {x.size(0)}\")  # Should be 64\n",
        "       # print(f\"Output batch size: {x.size(0)}\")  # Should also be 64\n",
        "        return x"
      ],
      "metadata": {
        "id": "EO-ysovugcVO"
      },
      "id": "EO-ysovugcVO",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpressionNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):   # Default parameter adjusted for 4 classes\n",
        "        super(ExpressionNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)  # Added padding to maintain size\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)  # Added padding to maintain size\n",
        "        # Adjusted based on pooling and padding, assuming input image size allows for this after conv and pool\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)  # Adjusted to correct size\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # Ensure the flattening matches the output size of the final pool layer\n",
        "        x = x.view(-1, 16 * 8 * 8)  # Adjust this based on your actual dimensions\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kR6HtPFEgcgI"
      },
      "id": "kR6HtPFEgcgI",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRYfBFXB7wld"
      },
      "id": "iRYfBFXB7wld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "086b69c3",
      "metadata": {
        "id": "086b69c3"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data, target in tqdm(train_loader, desc=\"Training\"):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Training loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader, desc=\"Testing\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        # Build a list of samples and labels by parsing filenames\n",
        "        for filename in os.listdir(root):\n",
        "            if filename.endswith('.pgm'):\n",
        "                # Example filename: 'mitchell_left_angry_open.pgm'\n",
        "                parts = filename.split('_')\n",
        "                label = parts[2] if len(parts) > 2 else None  # Extract expression label\n",
        "                self.samples.append((os.path.join(root, filename), label))\n",
        "\n",
        "        # Map expressions to integer labels\n",
        "        expressions = sorted(set(label for _, label in self.samples))\n",
        "        self.class_to_idx = {expression: i for i, expression in enumerate(expressions)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, expression = self.samples[idx]\n",
        "        image = default_loader(path)  # Uses PIL to load the image\n",
        "        label = self.class_to_idx[expression]  # Convert expression to a numerical label\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "59VR_p_zpq7X"
      },
      "id": "59VR_p_zpq7X",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_for_mitchell(dataset, model, device):\n",
        "    model.eval()\n",
        "    indices = []\n",
        "    predictions = []  # To store prediction results for debugging\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        img, _ = dataset[i]\n",
        "        img = img.unsqueeze(0).to(device)  # Add batch dimension\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "        pred = output.argmax(dim=1)\n",
        "        predictions.append(pred.item())  # Store prediction\n",
        "\n",
        "        if pred.item() == 1:  # Assuming '1' indicates Mitchell\n",
        "            indices.append(i)\n",
        "\n",
        "    # Debugging: Print the distribution of predictions\n",
        "    print(\"Prediction distribution:\", {i: predictions.count(i) for i in set(predictions)})\n",
        "\n",
        "    # Check if indices list is empty\n",
        "    if not indices:\n",
        "        print(\"No items classified as Mitchell. Please check model predictions or adjust criteria.\")\n",
        "        # Optional: Instead of returning None, consider returning an empty Subset if it suits your application better\n",
        "        return Subset(dataset, [])  # This avoids TypeError when the calling function expects a dataset-like object\n",
        "    else:\n",
        "        print(f\"Items classified as Mitchell: {len(indices)}\")\n",
        "\n",
        "    return Subset(dataset, indices)"
      ],
      "metadata": {
        "id": "iduaO8opNU0Q"
      },
      "id": "iduaO8opNU0Q",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "79b19120",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "79b19120",
        "outputId": "93da543d-a888-4331-a771-6b4cf9a8f2ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 28\n",
            "Number of unique classes: 4\n",
            "Training dataset size: 22\n",
            "Testing dataset size: 6\n",
            "Sample shape: torch.Size([1, 32, 32]), Label: 3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-7642fbe72292>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Make sure this directory points to where your images are stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Pythoncode/W22/faces_4/mitchell'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-106-7642fbe72292>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch test dataloder  shape: {data.shape}, Batch target shape: {target.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Just to test the first batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler\n",
        "\n",
        "def main(data_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Initialize your custom dataset\n",
        "    dataset = CustomImageDataset(root=data_dir, transform=transform)\n",
        "    print(f\"Total dataset size: {len(dataset)}\")\n",
        "\n",
        "    # Use the length of class_to_idx to determine the number of unique classes\n",
        "    num_classes = len(dataset.class_to_idx)\n",
        "    print(f\"Number of unique classes: {num_classes}\")\n",
        "\n",
        "    # Splitting the dataset into train and test\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Testing dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    test_sample, test_label = test_dataset[0]  # Adjust index as necessary\n",
        "    print(f\"Sample shape: {test_sample.shape}, Label: {test_label}\")\n",
        "\n",
        "\n",
        "    # Create DataLoader instances\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "    #test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
        "\n",
        "    # Example of a diagnostic step, not a solution\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, sampler=SubsetRandomSampler(range(17)))\n",
        "\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        print(f\"Batch test dataloder  shape: {data.shape}, Batch target shape: {target.shape}\")\n",
        "        break  # Just to test the first batch\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        print(f\"Direct Test DataLoader Check - Batch data shape: {data.shape}, Batch target shape: {target.shape}\")\n",
        "        break  # Just to confirm we can get at least one batch\n",
        "\n",
        "\n",
        "    # Train MitchellNet\n",
        "    mitchell_model = MitchellNet().to(device)\n",
        "    optimizer_mitchell = optim.SGD(mitchell_model.parameters(), lr=0.01, momentum=0.9)\n",
        "    for epoch in range(1, 11):\n",
        "        train(mitchell_model, device, train_loader, optimizer_mitchell)\n",
        "        test(mitchell_model, device, test_loader)\n",
        "\n",
        "    # Filter dataset based on MitchellNet's predictions\n",
        "    mitchell_filtered_dataset = filter_for_mitchell(dataset, mitchell_model, device)\n",
        "\n",
        "    # Prepare DataLoader for filtered dataset\n",
        "    filtered_loader = DataLoader(mitchell_filtered_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "\"\"\"\n",
        "    # Train ExpressionNet\n",
        "    expression_model = ExpressionNet(num_classes=num_classes).to(device)\n",
        "    optimizer_expression = optim.SGD(expression_model.parameters(), lr=0.01, momentum=0.9)\n",
        "    for epoch in range(1, 11):\n",
        "        train(expression_model, device, filtered_loader, optimizer_expression)\n",
        "        # Note: You might want to adjust how you handle the test set here, depending on your needs\n",
        "\n",
        "    # Save the model checkpoints\n",
        "    torch.save(mitchell_model.state_dict(), \"mitchell_model_checkpoint.pth\")\n",
        "    torch.save(expression_model.state_dict(), \"expression_model_checkpoint.pth\")\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Make sure this directory points to where your images are stored\n",
        "    data_dir = '/content/gdrive/My Drive/Pythoncode/W22/faces_4/mitchell'\n",
        "    main(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(data_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                                    transforms.Resize((32, 32)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    dataset = CustomImageDataset(root=data_dir, transform=transform)\n",
        "    num_classes = len(dataset.class_to_idx)\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    model = Net(num_classes=num_classes).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Decays the learning rate every 10 epochs\n",
        "\n",
        "    for epoch in range(1, 11):\n",
        "        print(f\"Epoch {epoch}/{10}\")\n",
        "        train(model, device, train_loader, optimizer)\n",
        "        test(model, device, test_loader)\n",
        "        scheduler.step()  # Adjust the learning rate\n",
        "\n",
        "    # Save the model checkpoints\n",
        "    torch.save(model.state_dict(), \"model_checkpoint.pth\")\n",
        "\n",
        "    print(\"Training completed\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Make sure this directory points to where your images are stored\n",
        "    data_dir = '/content/gdrive/My Drive/Pythoncode/W22/faces/mitchell'\n",
        "    main(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtezsR1G-dF",
        "outputId": "184131f5-ba3e-458a-fe30-9d3675c2e70a"
      },
      "id": "VrtezsR1G-dF",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3744913339614868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.3883, Accuracy: 5/17 (29%)\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3768696784973145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.3907, Accuracy: 5/17 (29%)\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3826159238815308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.3943, Accuracy: 5/17 (29%)\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3487340211868286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.3980, Accuracy: 5/17 (29%)\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.4275745749473572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4004, Accuracy: 5/17 (29%)\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3745765686035156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4012, Accuracy: 5/17 (29%)\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.396196722984314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4024, Accuracy: 5/17 (29%)\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3951307535171509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4042, Accuracy: 5/17 (29%)\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3787712454795837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4059, Accuracy: 5/17 (29%)\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.3715495467185974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 1.4069, Accuracy: 5/17 (29%)\n",
            "Training completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}