{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf539e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Required activity 8.1: Predicting plant types\n",
    "The following data provided is a small subset of the famous Iris database Links to an external site., first used by Sir R. A. Fisher. This is perhaps the best known database in the pattern recognition literature. Fisher’s paper (R. A. Fisher (1936), The Use of Multiple Measurements in Taxonomic Problems Links to an external site., Annals of Eugenics 7(2):179–188) is a classic in the field and is referenced frequently to this day. The data set contains three classes of 50 instances each, where each class refers to a type of iris plant. There are four features: sepal length, sepal width, petal length and petal width.\n",
    "For the exercise, we will only use the sepal length and the sepal width.\n",
    "Iris database subset\n",
    "Sepal length\tSepal width\tClass\n",
    "6.3\t2.9\tvirginica\n",
    "5.1\t3.4\tsetosa\n",
    "5.7\t2.5\tvirginica\n",
    "5.0\t3.5\tsetosa\n",
    "4.8\t3.4\tsetosa\n",
    "6.6\t2.9\tversicolor\n",
    "6.3\t3.3\tversicolor\n",
    "6.3\t3.4\tversicolor\n",
    "6.0\t3.4\tversicolor\n",
    "4.7\t3.2\t???\n",
    "5.0\t3.3\t???\n",
    "6.1\t2.9\t???\n",
    "6.8\t3.2\t???\n",
    "4.5\t2.3\t???\n",
    "7.7\t3.0\t???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1c826",
   "metadata": {},
   "source": [
    "Here’s what you need to do:\n",
    "(A) Normalise the data using z-score normalisation.\n",
    "Note: For the purpose of this exercise, please use all the data to compute µ and σ required for the normalisation. However, keep in mind that in reality you have to use only the training data to compute µ and σ . The input for future predictions will typically not be available to you yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79840df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n",
      "[[ 0.5710252  -0.60517333]\n",
      " [-0.7814029   0.85895569]\n",
      " [-0.10518885 -1.77647654]\n",
      " [-0.89410524  1.15178149]\n",
      " [-1.11950993  0.85895569]\n",
      " [ 0.90913222 -0.60517333]\n",
      " [ 0.5710252   0.56612989]\n",
      " [ 0.5710252   0.85895569]\n",
      " [ 0.23291817  0.85895569]\n",
      " [-1.23221227  0.27330408]\n",
      " [-0.89410524  0.56612989]\n",
      " [ 0.34562051 -0.60517333]\n",
      " [ 1.1345369   0.27330408]\n",
      " [-1.45761695 -2.36212815]\n",
      " [ 2.14885798 -0.31234752]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Your dataset\n",
    "data = np.array([\n",
    "    [6.3, 2.9, 'virginica'],\n",
    "    [5.1, 3.4, 'setosa'],\n",
    "    [5.7, 2.5, 'virginica'],\n",
    "    [5.0, 3.5, 'setosa'],\n",
    "    [4.8, 3.4, 'setosa'],\n",
    "    [6.6, 2.9, 'versicolor'],\n",
    "    [6.3, 3.3, 'versicolor'],\n",
    "    [6.3, 3.4, 'versicolor'],\n",
    "    [6.0, 3.4, 'versicolor'],\n",
    "    [4.7, 3.2, None],\n",
    "    [5.0, 3.3, None],\n",
    "    [6.1, 2.9, None],\n",
    "    [6.8, 3.2, None],\n",
    "    [4.5, 2.3, None],\n",
    "    [7.7, 3.0, None]\n",
    "])\n",
    "\n",
    "# Extracting numeric data for normalization\n",
    "numeric_data = np.array([x[:2] for x in data]).astype(float)\n",
    "\n",
    "# Apply z-score normalization\n",
    "normalized_data = zscore(numeric_data, axis=0)\n",
    "\n",
    "# Display normalized data\n",
    "print(\"Normalized Data:\")\n",
    "print(normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca622c",
   "metadata": {},
   "source": [
    "(B) Use the k-nearest neighbours method with k=3 to predict the missing classes. Use the Euclidean norm in your distance calculations.\n",
    "Note: When making predictions, you need to transform the input data for the predictions using the same µ and σ required as for the transformation of the data in (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7122da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with predicted classes:\n",
      "[[6.3 2.9 'virginica']\n",
      " [5.1 3.4 'setosa']\n",
      " [5.7 2.5 'virginica']\n",
      " [5.0 3.5 'setosa']\n",
      " [4.8 3.4 'setosa']\n",
      " [6.6 2.9 'versicolor']\n",
      " [6.3 3.3 'versicolor']\n",
      " [6.3 3.4 'versicolor']\n",
      " [6.0 3.4 'versicolor']\n",
      " [4.7 3.2 'setosa']\n",
      " [5.0 3.3 'setosa']\n",
      " [6.1 2.9 'versicolor']\n",
      " [6.8 3.2 'versicolor']\n",
      " [4.5 2.3 'setosa']\n",
      " [7.7 3.0 'versicolor']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Your dataset\n",
    "data = np.array([\n",
    "    [6.3, 2.9, 'virginica'],\n",
    "    [5.1, 3.4, 'setosa'],\n",
    "    [5.7, 2.5, 'virginica'],\n",
    "    [5.0, 3.5, 'setosa'],\n",
    "    [4.8, 3.4, 'setosa'],\n",
    "    [6.6, 2.9, 'versicolor'],\n",
    "    [6.3, 3.3, 'versicolor'],\n",
    "    [6.3, 3.4, 'versicolor'],\n",
    "    [6.0, 3.4, 'versicolor'],\n",
    "    [4.7, 3.2, None],\n",
    "    [5.0, 3.3, None],\n",
    "    [6.1, 2.9, None],\n",
    "    [6.8, 3.2, None],\n",
    "    [4.5, 2.3, None],\n",
    "    [7.7, 3.0, None]\n",
    "])\n",
    "\n",
    "# Separating the dataset into features (X) and target (y)\n",
    "X = np.array([x[:2] for x in data if x[2] is not None]).astype(float)\n",
    "y = np.array([x[2] for x in data if x[2] is not None])\n",
    "\n",
    "# Data to predict\n",
    "X_predict = np.array([x[:2] for x in data if x[2] is None]).astype(float)\n",
    "\n",
    "# Create KNN model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_predict)\n",
    "\n",
    "# Add predictions back to the dataset\n",
    "prediction_index = 0  # Counter for the predictions\n",
    "for i, row in enumerate(data):\n",
    "    if row[2] is None:\n",
    "        row[2] = predictions[prediction_index]\n",
    "        prediction_index += 1\n",
    "\n",
    "print(\"Updated dataset with predicted classes:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f74674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
