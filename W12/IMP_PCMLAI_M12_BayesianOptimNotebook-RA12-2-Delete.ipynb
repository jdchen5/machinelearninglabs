{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SwBZjG_GUyH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYwyi0m3zELD"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we will remind ourselves of everything we have learned in the course, and we put YOU in the place of a black-box optimizer. Throughout, we will be asking you to query black-box functions manually, to try and find intuition for the way Bayesian Optimization works.\n",
    "\n",
    "We begin with 'The Bayesian Optimization Problem', where we try to put ourselves in the place of a black-box optimizer. This gives us an intuitive understanding of why the problem is difficult, and how we may be able to solve it.\n",
    "\n",
    "We then introduce the idea of surrogate models, and show how they can act as guides for our belief and uncertainty on modelling black-box problems. With a surrogate model, the task of solving the optimization problem should become easier.\n",
    "\n",
    "Ideally, by this step you should have developed some 'rules' about the way you use the surrogate model to select the next queries. We can formalize this mathematically, and create a method that automatically chooses the next query - i.e. Bayesian Optimization!\n",
    "\n",
    "In the final exercises, which you should submit, we ask you to write and explore the properties of two new acquisition functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRRb5fGpQq0A"
   },
   "source": [
    "## The Bayesian Optimization Problem\n",
    "\n",
    "Recall that Bayesian Optimization concerns the problem of maximizing expensive black-box functions. \n",
    "\n",
    "In particular, we are trying to find:\n",
    "\n",
    "$$x_* = \\arg\\max f(x)$$\n",
    "\n",
    "We have no information about the function we want to optimise, but we are able to *query* the function at any input location, $x$. We want to try to get as close as possible to the maximum, with the least number of queries as possible. \n",
    "\n",
    "To get an intuitive understanding of the problem, and possible solutions, try the exercise below.\n",
    "\n",
    "Running the cell will activate a loop where you are requested to input a number in the interval [0, 1]. You have ten attempts to try and maximize an unknown function. Since you are dealing with a black-box function, you will only be able to see the queries you have chosen, $x_i$, and the corresponding observations, $f(x_i)$. Re-run the cell as many times as you want, and try to consider the following questions:\n",
    "\n",
    "1. How is this different from classical optimisation? (hint: can you use gradients?)\n",
    "2. What are the main difficulties you encounter when optimizing?\n",
    "3. What strategies have you developed to solve the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXUaNq-bGqaQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw a random function parameters\n",
    "modes = np.random.randint(1, 5)\n",
    "std = np.random.uniform(low = 0.005, high = 0.05, size = modes)\n",
    "means = np.random.uniform(size = modes)\n",
    "amps = np.random.uniform(size = modes) * (2 - 1) + 1\n",
    "\n",
    "# define function: This is the unknown, black-box function that the user tries to optimize. \n",
    "#It takes an input x and returns a value, calculated based on the previously set random parameters.\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "\n",
    "# initalise query lists and maximum observations\n",
    "X, Y = [], []\n",
    "max_obs = 0\n",
    "\n",
    "# how many queries in optimisation loop?\n",
    "num_queries = 10\n",
    "\n",
    "for i in range(0, num_queries):\n",
    "  # clear outputs, to keep interface clean\n",
    "  clear_output(wait = True)\n",
    "  # initalise plots\n",
    "  fig, ax = plt.subplots(figsize = (15, 7))\n",
    "  # set x, y limits, labels and dynamic title\n",
    "  ax.set_xlim(0, 1)\n",
    "  ax.set_ylim(0, max(max_obs + 1, 3))\n",
    "  ax.set_ylabel('f(x)')\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_title('So far you have selected ' + str(i) + ' queries, you have ' + str(10 - i) + ' left.' )\n",
    "  # plot queries, show plot\n",
    "  ax.scatter(X, Y, c = 'r', marker='x', s = 100)\n",
    "  plt.show()\n",
    "  # initalise x\n",
    "  x = -1\n",
    "  # select display format of X and Y\n",
    "  X_format =  ['%.2f' % query for query in X] # 2 sig figs\n",
    "  Y_format = ['%.4f' % obs for obs in Y] # 4 sig figs\n",
    "\n",
    "  while not (0 <= x <= 1): # condition to ensure a number between 0 and 1 is chosen\n",
    "    data = [(query, obs) for query, obs in zip(X_format, Y_format)]\n",
    "    print('Data so far (sorted by descending observations): ')\n",
    "    print('\\n'.join('{}: (x, f(x)) = {}'.format(*k) for k in enumerate(data, start = 1))) # display data\n",
    "    x = float(input('Pick a number between 0 and 1: '))\n",
    "  # append data, calculate function and sort lists according to observation values\n",
    "  X.append(x)\n",
    "  y = calc_function(x)\n",
    "  Y.append(y)\n",
    "  X = [x for _, x in sorted(zip(Y, X), reverse = True)]\n",
    "  Y.sort(reverse = True)\n",
    "  max_obs = max(max_obs, y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# calculate function in the grid [0, 0.01, 0.02, ..., 0.98, 0.99, 1]\n",
    "x_grid = np.linspace(0, 1, 1001)\n",
    "y_real = []\n",
    "best_obs_grid = 0\n",
    "for x in x_grid:\n",
    "  y = calc_function(x)\n",
    "  y_real.append(y)\n",
    "  best_obs_grid = max(best_obs_grid, y) # keep track of best observation\n",
    "\n",
    "\n",
    "# final plot and display\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "ax.plot(x_grid, y_real, 'k', label = 'f(x)')\n",
    "ax.scatter(X, Y, c = 'r', marker = 'x', label = 'Queries', s = 100)\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_title('Real function and all queries')\n",
    "plt.show()\n",
    "print('Maximum (by Grid-Search):')\n",
    "print(best_obs_grid)\n",
    "print('Best by Yourself:')\n",
    "print(max_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlaRFIklVITK"
   },
   "source": [
    "# Surrogate Models #\n",
    "\n",
    "Hopefully by the end of the exercise you began to develop a strategy which leveraged a balance between exploration and exploitation. You explore when you have very little information about a particular area of the search space. You exploit, once you have found a large observation, and begin to investigate the area around. \n",
    "\n",
    "Surrogate models allow us to develop an algorithm which is able to 'think' like this. The surrogate model gives us a mathematical representation of our *belief* and *certainty* of how the black-box function looks like. The most common one is the Gaussian Process. Recall its definition:\n",
    "\n",
    "Consider some space $\\mathcal{X}$. Consider a function $\\mu: \\mathcal{X} \\rightarrow \\mathbb{R}$, and a *positive semi-definite* function $\\kappa : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$.\n",
    "\n",
    "We say $f$ follows a Gaussian Process prior with mean function $\\mu$ and kernel $\\kappa$, if, for any $n \\in \\mathbb{N}$, and for any collection of distinct points $(x_1, x_2, ..., x_n) := x$, $x_i \\in \\mathcal{X}$, the random vector $(f(x_1), ..., f(x_n))$ is normally distributed with mean $m(x)$ and covariance matrix $K(x)$ where:\n",
    "\n",
    "$$\n",
    "m(x)_i = \\mu(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "K(x)_{i, j} = \\kappa(x_i, x_j)\n",
    "$$\n",
    "\n",
    "We write $f \\sim \\mathcal{GP}(\\mu(x), \\kappa(x))$.\n",
    "\n",
    "What makes Gaussian Processes so desirable, is the fact that we can calculate the posterior analytically, *even under the assumption of noise observations*. To be more precise, assume we have a problem of the form:\n",
    "\n",
    "$$\n",
    " y = f(x) + \\epsilon\n",
    "$$\n",
    "\n",
    "Where $\\epsilon \\sim \\text{Normal}(0, \\sigma_e^2)$ represents the noise. Assume further that $f \\sim \\mathcal{GP}(\\mu_0, \\kappa_0)$, and that we are given a data-set of queries and observations, $D_n = \\{ (x_i, y_i) : i = 1, ..., n \\}$.\n",
    "\n",
    "It then follows that the posterior, $f \\ | \\ D_n$, is also a Gaussian Process, with mean and kernel functions given by:\n",
    "\n",
    "$$\n",
    "    m_n(x) = \\mu_0(x) + k(x)^T( K + \\sigma^2 I )^{-1} (Y - m)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    s^2_n(x, x') = \\kappa_0(x, x') - k(x)^T ( K + \\sigma^2 I ) ^{-1} k(x')\n",
    "$$\n",
    "\n",
    "Where: $m_i = \\mu_0(x_i), Y_i = y_i, k(x)_i = \\kappa_0(x, x_i), K_{ij} = \\kappa_0(x_i, x_j)$\n",
    "\n",
    "We will now repeat the previous exercise, but plotting a surrogate Gaussian Process to fit the selected observations. We will be using an RBF kernel, which has a single parameter (in 1D) called the length-scale. Repeat the exercise a few times. Focus on the following questions:\n",
    "1. How can you interpret the model? How does the model respond to new observations? Can you justify why it is standard to use zero as a prior mean?\n",
    "2. Can you think of rule(s) that choose the next point, using only the posterior as reference (i.e. without human intervention)?\n",
    "3. Play around with the parameters of the problem (see very first lines of code cell). How does changing the lengthscale affect the behaviour of the model? How does it respond to noise?\n",
    "\n",
    "Note: Recall that the hyper-parameters of the kernel can be chosen by maximum likelihood estimation. We do not do that here, we keep them fixed, so you can get a better understanding of how they affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFWrjzlqLkpX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters of the problem. Feel free to change them and play around with them\n",
    "real_noise_std = 1e-10 # real noise needs to be positive for code to work, instead of zero set 1e-10\n",
    "noise_assumption = 1e-10 # noise assumption, a hyper-parameter\n",
    "\n",
    "rbf_lengthscale = 0.1 # lengthscale parameter\n",
    "\n",
    "# draw a random function parameters\n",
    "modes = np.random.randint(1, 5)\n",
    "std = np.random.uniform(low = 0.005, high = 0.05, size = modes)\n",
    "means = np.random.uniform(size = modes)\n",
    "amps = np.random.uniform(size = modes) * (2 - 1) + 1\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "\n",
    "# define kernel of GP\n",
    "#kernel: The GP uses an RBF (Radial Basis Function) kernel, which measures similarity or correlation between points in the input space. \n",
    "#The length_scale parameter of the RBF kernel controls how smooth the GP's predictions are; smaller values lead to more wiggly functions, larger values to smoother functions.\n",
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "#Alpha: This parameter represents the noise level in the GP model. It's used to add uncertainty to the GP's predictions, which helps the model account for noise in the observations.\n",
    "model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "# standard devation for plot\n",
    "beta = 1.96\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "# initalise query lists and maximum observations\n",
    "X, Y = [], []\n",
    "max_obs = 0\n",
    "# initalise grid for plots\n",
    "x_grid = np.linspace(0, 1, 101).reshape(-1, 1)\n",
    "\n",
    "# how many queries in optimisation loop?\n",
    "num_queries = 10\n",
    "\n",
    "for i in range(0, num_queries):\n",
    "  # clear outputs, to keep interface clean\n",
    "  clear_output(wait = True)\n",
    "  model = GaussianProcessRegressor(kernel = kernel)\n",
    "  # fit model\n",
    "  if i != 0:\n",
    "    model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "  # calculate mean and standard devation, make them one-dimensional for plotting\n",
    "  post_mean, post_std = model.predict(x_grid, return_std=True)\n",
    "  post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "  # initalise plots\n",
    "  fig, ax = plt.subplots(figsize = (15, 7))\n",
    "  # set x, y limits, labels and dynamic title\n",
    "  ax.set_xlim(0, 1)\n",
    "  ax.set_ylim(0, max(max_obs + 1, 3))\n",
    "  ax.set_ylabel('f(x)')\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_title('So far you have selected ' + str(i) + ' queries, you have ' + str(10 - i) + ' left.' )\n",
    "  # plot queries\n",
    "  ax.scatter(X, Y, c = 'r', marker='x', s = 100)\n",
    "  # plot mean and standard deviations\n",
    "  ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "  ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "  ax.legend()\n",
    "  plt.show()\n",
    "  # initalise x\n",
    "  x = -1\n",
    "  # select display format of X and Y\n",
    "  X_format =  ['%.2f' % query for query in X] # 2 sig figs\n",
    "  Y_format = ['%.4f' % obs for obs in Y] # 4 sig figs\n",
    "\n",
    "  while not (0 <= x <= 1): # condition to ensure a number between 0 and 1 is chosen\n",
    "    data = [(query, obs) for query, obs in zip(X_format, Y_format)]\n",
    "    print('Data so far (sorted by descending observations): ')\n",
    "    print('\\n'.join('{}: (x, f(x)) = {}'.format(*k) for k in enumerate(data, start = 1))) # display data\n",
    "    x = float(input('Pick a number between 0 and 1: '))\n",
    "  # append data, calculate function and sort lists according to observation values\n",
    "  X.append(x)\n",
    "  y = calc_function(x) + np.random.normal(scale = real_noise_std)\n",
    "  Y.append(y)\n",
    "  X = [x for _, x in sorted(zip(Y, X), reverse = True)]\n",
    "  Y.sort(reverse = True)\n",
    "  max_obs = max(max_obs, y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# calculate function in the grid [0, 0.01, 0.02, ..., 0.98, 0.99, 1]\n",
    "x_grid = np.linspace(0, 1, 1001)\n",
    "y_real = []\n",
    "best_obs_grid = 0\n",
    "for x in x_grid:\n",
    "  y = calc_function(x)\n",
    "  y_real.append(y)\n",
    "  best_obs_grid = max(best_obs_grid, y) # keep track of best observation\n",
    "\n",
    "\n",
    "# final GP posterior\n",
    "model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "post_mean, post_std = model.predict(x_grid.reshape(-1, 1), return_std=True)\n",
    "post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "\n",
    "# final plot and display\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "ax.plot(x_grid, y_real, 'k', label = 'f(x)')\n",
    "ax.scatter(X, Y, c = 'r', marker = 'x', label = 'Queries', s = 100)\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(bottom = 0)\n",
    "ax.set_title('Real function and all queries')\n",
    "ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print('Maximum (by Grid-Search):')\n",
    "print(best_obs_grid)\n",
    "print('Best by Yourself:')\n",
    "print(max_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4i-XKoEp3Md"
   },
   "source": [
    "# Acquisition Functions\n",
    "\n",
    "Once we have built a surrogate model, we can use it to create a rule for choosing the next query. We do this by *maximising* (or minimising) the acquisition function, we can do this because acquisition functions tend to be *much easier* to optimise, it is usually done using a mix of gradient methods or some kind of numerical procedure (e.g. Monte Carlo).\n",
    "\n",
    "One of the most basic acquisition functions, but very powerful in practice, is called the *upper confidence bound* acquisition function. It is defined by:\n",
    "$$\n",
    "\\alpha(x | D_n) = m_n(x) + \\beta \\cdot s_n(x)\n",
    "$$\n",
    "Where $\\beta$ is a parameter that controls the exploration-exploitation trade-off (higher $\\beta$ means more exploration). We can then choose the next point by the rule:\n",
    "$$\n",
    "x_{t+1} = \\arg\\max \\alpha(x | D_t)\n",
    "$$\n",
    "\n",
    "Run the code below and observe the algorithm in action. Consider the following questions:\n",
    "1. Can you see the next point that the algorithm will choose?\n",
    "2. Change the value of $\\beta$ at the beginning of the code. How does this affect the behavior of the algorithm?\n",
    "\n",
    "Note: We will be using grid-search to optimise the acquisition function. In this case, it seems pointless since we can optimise the objective function in the same way, just as fast. Recall that in practice, the objective function is expensive, and takes a long-time to evalutate, therefore grid search is unfeasible. The acquisition function can still be optimized very quickly in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJLJPNj9sd04",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters of the problem. Feel free to change them and play around with them\n",
    "real_noise_std = 1e-10 # needs to be positive for code to work, instead of zero set 1e-10\n",
    "noise_assumption = 1e-10\n",
    "\n",
    "rbf_lengthscale = 0.1\n",
    "\n",
    "# Acquisition Function Parameter:\n",
    "#Balances exploration and exploitation by considering both the GP's mean and uncertainty. The beta parameter determines the weight of the uncertainty in the decision-making process.\n",
    "beta = 1.96\n",
    "\n",
    "# draw a random function parameters\n",
    "modes = np.random.randint(1, 5)\n",
    "std = np.random.uniform(low = 0.005, high = 0.05, size = modes)\n",
    "means = np.random.uniform(size = modes)\n",
    "amps = np.random.uniform(size = modes) * (2 - 1) + 1\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "\n",
    "# define kernel of GP\n",
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "# initalise query lists and maximum observations\n",
    "X, Y = [], []\n",
    "max_obs = 0\n",
    "# initalise grid for plots\n",
    "x_grid = np.linspace(0, 1, 101).reshape(-1, 1)\n",
    "\n",
    "# how many queries in optimisation loop?\n",
    "num_queries = 10\n",
    "\n",
    "#Optimization Loop: For a set number of queries, the code fits the GP to the current data, plots the GP mean and uncertainty, and prompts the user to continue to the next point selection.\n",
    "for i in range(0, num_queries):\n",
    "  # clear outputs, to keep interface clean\n",
    "  clear_output(wait = True)\n",
    "  model = GaussianProcessRegressor(kernel = kernel)\n",
    "  # fit model\n",
    "  if i != 0:\n",
    "    model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "  # calculate mean and standard devation, make them one-dimensional for plotting\n",
    "  post_mean, post_std = model.predict(x_grid, return_std=True)\n",
    "  post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "  # initalise plots\n",
    "  fig, ax = plt.subplots(figsize = (15, 7))\n",
    "  # set x, y limits, labels and dynamic title\n",
    "  ax.set_xlim(0, 1)\n",
    "  ax.set_ylim(0, max(max_obs + 1, 3))\n",
    "  ax.set_ylabel('f(x)')\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_title('So far you have selected ' + str(i) + ' queries, you have ' + str(10 - i) + ' left.' )\n",
    "  # plot queries\n",
    "  ax.scatter(X, Y, c = 'r', marker='x', s = 100)\n",
    "  # plot mean and standard deviations\n",
    "  ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "  ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "  ax.legend()\n",
    "  plt.show()\n",
    "  # initalise x\n",
    "  x = -1\n",
    "  # select display format of X and Y\n",
    "  X_format =  ['%.2f' % query for query in X] # 2 sig figs\n",
    "  Y_format = ['%.4f' % obs for obs in Y] # 4 sig figs\n",
    "\n",
    "  data = [(query, obs) for query, obs in zip(X_format, Y_format)]\n",
    "  print('Data so far (sorted by descending observations): ')\n",
    "  print('\\n'.join('{}: (x, f(x)) = {}'.format(*k) for k in enumerate(data, start = 1))) # display data\n",
    "  _ = input('Input anything to see the next chosen point') # we are using this to allow for the user to change plots\n",
    "\n",
    "  # MODIFY THE CODE IN THIS AREA\n",
    "  #######################################################\n",
    "  acquisition_function = post_mean + beta * post_std\n",
    "  #######################################################\n",
    "  if i == 0:\n",
    "    x = np.random.uniform(0, 1) # first observation is chosen randomly\n",
    "  else:\n",
    "    #remove single-dimensional entries from the shape of an array. commonly used when the data must be in a one-dimensional format to be processed by certain functions or methods, such as plotting functions or when you want to iterate over the array without dealing with unnecessary nested array structures.\n",
    "    grid = x_grid.squeeze()\n",
    "    #The next point x is chosen by finding the maximum of the acquisition function. \n",
    "    x = grid[np.argmax(acquisition_function)] # else use the acquisition function\n",
    "\n",
    "  # append data, calculate function and sort lists according to observation values\n",
    "  X.append(x)\n",
    "  y = calc_function(x) + np.random.normal(scale = real_noise_std)\n",
    "  Y.append(y)\n",
    "  X = [x for _, x in sorted(zip(Y, X), reverse = True)]\n",
    "  Y.sort(reverse = True)\n",
    "  max_obs = max(max_obs, y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# calculate function in the grid [0, 0.01, 0.02, ..., 0.98, 0.99, 1]\n",
    "x_grid = np.linspace(0, 1, 1001)\n",
    "y_real = []\n",
    "best_obs_grid = 0\n",
    "for x in x_grid:\n",
    "  y = calc_function(x)\n",
    "  y_real.append(y)\n",
    "  best_obs_grid = max(best_obs_grid, y) # keep track of best observation\n",
    "\n",
    "\n",
    "# final GP posterior\n",
    "model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "post_mean, post_std = model.predict(x_grid.reshape(-1, 1), return_std=True)\n",
    "post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "\n",
    "# final plot and display\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "ax.plot(x_grid, y_real, 'k', label = 'f(x)')\n",
    "ax.scatter(X, Y, c = 'r', marker = 'x', label = 'Queries', s = 100)\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(bottom = 0)\n",
    "ax.set_title('Real function and all queries')\n",
    "ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print('Maximum (by Grid-Search):')\n",
    "print(best_obs_grid)\n",
    "print('UCB (Acquisition Function by Grid-Search):')\n",
    "print(max_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xBqIPQ6zELP"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Modify the code in the cell directly above to implement an acquisition function which selects the point with the largest posterior *variance*. Alternately, you can use the standard deviation.\n",
    "\n",
    "More challenging:\n",
    "\n",
    "2. An intuitive acquisition function is called 'Probabilty of Improvement' (PI). It is given by:\n",
    "$$ \\alpha(x)_{PI} = \\mathbb{P}(f(x) > y_{max})$$\n",
    "Where $y_{max}$ is our best observation so far. Code this acquisition function.\n",
    "\n",
    "3. You may have found that PI is *very exploitative*. Fix this, by adding an 'exploration term':\n",
    "$$ \\alpha(x)_{\\eta PI} = \\mathbb{P}(x > y_{max} + \\eta)$$\n",
    "How does it compare now? How may you go about choosing this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modify the code in the cell directly above to implement an acquisition function which selects the point with the largest posterior *variance*. Alternately, you can use the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Modify the code in the cell directly above to implement an acquisition function which selects the point with the largest posterior variance. Alternately, you can use the standard deviation.\n",
    "\n",
    "# Parameters of the problem. Feel free to change them and play around with them\n",
    "real_noise_std = 1e-10 # needs to be positive for code to work, instead of zero set 1e-10\n",
    "noise_assumption = 1e-10\n",
    "\n",
    "rbf_lengthscale = 0.1\n",
    "\n",
    "# Acquisition Function Parameter:\n",
    "#Balances exploration and exploitation by considering both the GP's mean and uncertainty. The beta parameter determines the weight of the uncertainty in the decision-making process.\n",
    "beta = 1.96\n",
    "\n",
    "# draw a random function parameters\n",
    "modes = np.random.randint(1, 5)\n",
    "std = np.random.uniform(low = 0.005, high = 0.05, size = modes)\n",
    "means = np.random.uniform(size = modes)\n",
    "amps = np.random.uniform(size = modes) * (2 - 1) + 1\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "\n",
    "# define kernel of GP\n",
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "# initalise query lists and maximum observations\n",
    "X, Y = [], []\n",
    "max_obs = 0\n",
    "# initalise grid for plots\n",
    "x_grid = np.linspace(0, 1, 101).reshape(-1, 1)\n",
    "\n",
    "# how many queries in optimisation loop?\n",
    "num_queries = 10\n",
    "\n",
    "#Optimization Loop: For a set number of queries, the code fits the GP to the current data, plots the GP mean and uncertainty, and prompts the user to continue to the next point selection.\n",
    "for i in range(0, num_queries):\n",
    "  # clear outputs, to keep interface clean\n",
    "  clear_output(wait = True)\n",
    "  model = GaussianProcessRegressor(kernel = kernel)\n",
    "  # fit model\n",
    "  if i != 0:\n",
    "    model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "  # calculate mean and standard devation, make them one-dimensional for plotting\n",
    "  post_mean, post_std = model.predict(x_grid, return_std=True)\n",
    "  post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "  # initalise plots\n",
    "  fig, ax = plt.subplots(figsize = (15, 7))\n",
    "  # set x, y limits, labels and dynamic title\n",
    "  ax.set_xlim(0, 1)\n",
    "  ax.set_ylim(0, max(max_obs + 1, 3))\n",
    "  ax.set_ylabel('f(x)')\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_title('So far you have selected ' + str(i) + ' queries, you have ' + str(10 - i) + ' left.' )\n",
    "  # plot queries\n",
    "  ax.scatter(X, Y, c = 'r', marker='x', s = 100)\n",
    "  # plot mean and standard deviations\n",
    "  ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "  ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "  ax.legend()\n",
    "  plt.show()\n",
    "  # initalise x\n",
    "  x = -1\n",
    "  # select display format of X and Y\n",
    "  X_format =  ['%.2f' % query for query in X] # 2 sig figs\n",
    "  Y_format = ['%.4f' % obs for obs in Y] # 4 sig figs\n",
    "\n",
    "  data = [(query, obs) for query, obs in zip(X_format, Y_format)]\n",
    "  print('Data so far (sorted by descending observations): ')\n",
    "  print('\\n'.join('{}: (x, f(x)) = {}'.format(*k) for k in enumerate(data, start = 1))) # display data\n",
    "  _ = input('Input anything to see the next chosen point') # we are using this to allow for the user to change plots\n",
    "\n",
    "  # MODIFY THE CODE IN THIS AREA\n",
    "  #######################################################\n",
    "  acquisition_function = post_std\n",
    "  #######################################################\n",
    "  if i == 0:\n",
    "    x = np.random.uniform(0, 1) # first observation is chosen randomly\n",
    "  else:\n",
    "    grid = x_grid.squeeze()\n",
    "    #The next point x is chosen by finding the maximum of the acquisition function. \n",
    "    x = grid[np.argmax(acquisition_function)] # else use the acquisition function\n",
    "\n",
    "  # append data, calculate function and sort lists according to observation values\n",
    "  X.append(x)\n",
    "  y = calc_function(x) + np.random.normal(scale = real_noise_std)\n",
    "  Y.append(y)\n",
    "  X = [x for _, x in sorted(zip(Y, X), reverse = True)]\n",
    "  Y.sort(reverse = True)\n",
    "  max_obs = max(max_obs, y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# calculate function in the grid [0, 0.01, 0.02, ..., 0.98, 0.99, 1]\n",
    "x_grid = np.linspace(0, 1, 1001)\n",
    "y_real = []\n",
    "best_obs_grid = 0\n",
    "for x in x_grid:\n",
    "  y = calc_function(x)\n",
    "  y_real.append(y)\n",
    "  best_obs_grid = max(best_obs_grid, y) # keep track of best observation\n",
    "\n",
    "\n",
    "# final GP posterior\n",
    "model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "post_mean, post_std = model.predict(x_grid.reshape(-1, 1), return_std=True)\n",
    "post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "\n",
    "# final plot and display\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "ax.plot(x_grid, y_real, 'k', label = 'f(x)')\n",
    "ax.scatter(X, Y, c = 'r', marker = 'x', label = 'Queries', s = 100)\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(bottom = 0)\n",
    "ax.set_title('Real function and all queries')\n",
    "ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print('Maximum (by Grid-Search):')\n",
    "print(best_obs_grid)\n",
    "print('UCB (Acquisition Function by Grid-Search):')\n",
    "print(max_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More challenging:\n",
    "\n",
    "2. An intuitive acquisition function is called 'Probabilty of Improvement' (PI). It is given by:\n",
    "$$ \\alpha(x)_{PI} = \\mathbb{P}(f(x) > y_{max})$$\n",
    "Where $y_{max}$ is our best observation so far. Code this acquisition function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data so far (sorted by descending observations): \n",
      "1: (x, f(x)) = ('0.01', '0.0013')\n",
      "Input anything to see the next chosen point0.9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m     PI_values \u001b[38;5;241m=\u001b[39m norm\u001b[38;5;241m.\u001b[39mcdf(Z_values)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Choose the next point to query by maximizing the PI acquisition function\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m[np\u001b[38;5;241m.\u001b[39margmax(PI_values)]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m#    grid = x_grid.squeeze()\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m#The next point x is chosen by finding the maximum of the acquisition function. \u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m#    x = grid[np.argmax(acquisition_function)] # else use the acquisition function\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m   \u001b[38;5;66;03m# append data, calculate function and sort lists according to observation values\u001b[39;00m\n\u001b[0;32m    100\u001b[0m   X\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters of the problem. Feel free to change them and play around with them\n",
    "real_noise_std = 1e-10 # needs to be positive for code to work, instead of zero set 1e-10\n",
    "noise_assumption = 1e-10\n",
    "\n",
    "rbf_lengthscale = 0.1\n",
    "\n",
    "# Acquisition Function Parameter:\n",
    "#Balances exploration and exploitation by considering both the GP's mean and uncertainty. The beta parameter determines the weight of the uncertainty in the decision-making process.\n",
    "beta = 1.96\n",
    "\n",
    "# draw a random function parameters\n",
    "modes = np.random.randint(1, 5)\n",
    "std = np.random.uniform(low = 0.005, high = 0.05, size = modes)\n",
    "means = np.random.uniform(size = modes)\n",
    "amps = np.random.uniform(size = modes) * (2 - 1) + 1\n",
    "\n",
    "# define function\n",
    "def calc_function(x):\n",
    "  exp = -(x - means) ** 2 / std\n",
    "  y = amps * np.exp(exp)\n",
    "  return np.sum(y)\n",
    "\n",
    "# define kernel of GP\n",
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "model = GaussianProcessRegressor(kernel = kernel, alpha=noise_assumption)\n",
    "\n",
    "X, Y = [], []\n",
    "max_obs = 0\n",
    "# initalise grid for plots\n",
    "x_grid = np.linspace(0, 1, 101).reshape(-1, 1)\n",
    "\n",
    "# how many queries in optimisation loop?\n",
    "num_queries = 10\n",
    "\n",
    "\n",
    "\n",
    "#Optimization Loop: For a set number of queries, the code fits the GP to the current data, plots the GP mean and uncertainty, and prompts the user to continue to the next point selection.\n",
    "for i in range(0, num_queries):\n",
    "  # clear outputs, to keep interface clean\n",
    "  clear_output(wait = True)\n",
    "  model = GaussianProcessRegressor(kernel = kernel)\n",
    "  # fit model\n",
    "  if i != 0:\n",
    "    model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "    \n",
    "  if i > 0:\n",
    "        y_max = max(Y)  # The best observation so far\n",
    "\n",
    "  # calculate mean and standard devation, make them one-dimensional for plotting\n",
    "  post_mean, post_std = model.predict(x_grid, return_std=True)\n",
    "  post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "  # initalise plots\n",
    "  fig, ax = plt.subplots(figsize = (15, 7))\n",
    "  # set x, y limits, labels and dynamic title\n",
    "  ax.set_xlim(0, 1)\n",
    "  ax.set_ylim(0, max(max_obs + 1, 3))\n",
    "  ax.set_ylabel('f(x)')\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_title('So far you have selected ' + str(i) + ' queries, you have ' + str(10 - i) + ' left.' )\n",
    "  # plot queries\n",
    "  ax.scatter(X, Y, c = 'r', marker='x', s = 100)\n",
    "  # plot mean and standard deviations\n",
    "  ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "  ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "  ax.legend()\n",
    "  plt.show()\n",
    "  # initalise x\n",
    "  x = -1\n",
    "  # select display format of X and Y\n",
    "  X_format =  ['%.2f' % query for query in X] # 2 sig figs\n",
    "  Y_format = ['%.4f' % obs for obs in Y] # 4 sig figs\n",
    "\n",
    "  data = [(query, obs) for query, obs in zip(X_format, Y_format)]\n",
    "  print('Data so far (sorted by descending observations): ')\n",
    "  print('\\n'.join('{}: (x, f(x)) = {}'.format(*k) for k in enumerate(data, start = 1))) # display data\n",
    "  _ = input('Input anything to see the next chosen point') # we are using this to allow for the user to change plots\n",
    "\n",
    "  # MODIFY THE CODE IN THIS AREA\n",
    "  #######################################################\n",
    "  #acquisition_function = post_mean + beta * post_std\n",
    "  #######################################################\n",
    "  if i == 0:\n",
    "    x = np.random.uniform(0, 1) # first observation is chosen randomly\n",
    "  else:\n",
    "    # Calculate Z-values for the PI acquisition function\n",
    "    Z_values = (post_mean - y_max) / post_std\n",
    "    # Probability of Improvement for each point in the grid\n",
    "    PI_values = norm.cdf(Z_values)\n",
    "    # Choose the next point to query by maximizing the PI acquisition function\n",
    "    x = grid[np.argmax(PI_values)]\n",
    "    \n",
    "#    grid = x_grid.squeeze()\n",
    "    #The next point x is chosen by finding the maximum of the acquisition function. \n",
    "#    x = grid[np.argmax(acquisition_function)] # else use the acquisition function\n",
    "\n",
    "  # append data, calculate function and sort lists according to observation values\n",
    "  X.append(x)\n",
    "  y = calc_function(x) + np.random.normal(scale = real_noise_std)\n",
    "  Y.append(y)\n",
    "  X = [x for _, x in sorted(zip(Y, X), reverse = True)]\n",
    "  Y.sort(reverse = True)\n",
    "  max_obs = max(max_obs, y)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# calculate function in the grid [0, 0.01, 0.02, ..., 0.98, 0.99, 1]\n",
    "x_grid = np.linspace(0, 1, 1001)\n",
    "y_real = []\n",
    "best_obs_grid = 0\n",
    "for x in x_grid:\n",
    "  y = calc_function(x)\n",
    "  y_real.append(y)\n",
    "  best_obs_grid = max(best_obs_grid, y) # keep track of best observation\n",
    "\n",
    "\n",
    "# final GP posterior\n",
    "model.fit(np.array(X).reshape(-1, 1), np.array(Y).reshape(-1, 1))\n",
    "post_mean, post_std = model.predict(x_grid.reshape(-1, 1), return_std=True)\n",
    "post_mean, post_std = post_mean.squeeze(), post_std.squeeze()\n",
    "\n",
    "\n",
    "# final plot and display\n",
    "fig, ax = plt.subplots(figsize = (15, 7))\n",
    "ax.plot(x_grid, y_real, 'k', label = 'f(x)')\n",
    "ax.scatter(X, Y, c = 'r', marker = 'x', label = 'Queries', s = 100)\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(bottom = 0)\n",
    "ax.set_title('Real function and all queries')\n",
    "ax.plot(x_grid.squeeze(), post_mean, label = 'GP Posterior Mean')\n",
    "ax.fill_between(x_grid.squeeze(), post_mean - beta*post_std, post_mean + beta*post_std, alpha = 0.2, label = str(beta) + ' Standard Deviations')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print('Maximum (by Grid-Search):')\n",
    "print(best_obs_grid)\n",
    "print('UCB (Acquisition Function by Grid-Search):')\n",
    "print(max_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. You may have found that PI is *very exploitative*. Fix this, by adding an 'exploration term':\n",
    "$$ \\alpha(x)_{\\eta PI} = \\mathbb{P}(x > y_{max} + \\eta)$$\n",
    "How does it compare now? How may you go about choosing this parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IMP-PCMLAI-M12-BayesianOptimNotebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "d37abda7630e259e5026a5079657683a09f6e3d11473720762ebe7250c494840"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
