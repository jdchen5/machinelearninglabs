{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37a8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb751c",
   "metadata": {},
   "source": [
    "## VC Dimension\n",
    "We will give a brief introduction to the concept of VC Dimension of a hypothesis class. Our main reference text is ```Understanding Machine Learning: From Theory to Algorithms``` by Shai Ben-David and Shai Shalev-Shwartz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f0dd5",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "- $\\mathcal{X}$ is the domain set, where any (training/test) instance $x$ is a member of $\\mathcal{X}$.\n",
    "- $\\mathcal{Y}$ is label set, so that every training instance has a known label $y \\in \\mathcal{Y}$, and we would like to predict the label of the test instances. Assume for simplicity that $\\mathcal{Y} = \\{ 0,1 \\}$.\n",
    "- $\\mathcal{H}$ is the hypothesis class, which is a set of functions $h: \\mathcal{X} \\mapsto \\mathcal{Y}$. \n",
    "- $C = \\{c_1,\\ldots, c_m \\} \\subset \\mathcal{X}$ is a collection of instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b9d8f",
   "metadata": {},
   "source": [
    "#### Definition 1. Restriction of the hypothesis class $\\mathcal{H}$ to a set $C$: \n",
    "$$\\mathcal{H}_C = \\{(h(c_1), h(c_1), \\ldots, h(c_m) : h \\in \\mathcal{H} \\}.$$\n",
    "Notice that each function $h_C \\in \\mathcal{H}_C$ is a point in $\\{0,1\\}^{|C|}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141d912",
   "metadata": {},
   "source": [
    "#### Let us work a little bit on Definition 1 to understand what it really says.\n",
    "- Step 1: Let $\\mathcal{X} = [-5, 5]$ be a closed interval in $\\mathbb{R}$.  Let us construct a function $h_{t}(x)$ that returns $1$ if $x \\leq t$ and $0$ otherwise. So, the parameter $t$ that defines the function $h$ is a *threshold*, and if the input of $h_t$ is not larger than this threshold, then the function labels this point as $1$. As an example, think as you are classifying lightweight boxers, and if a boxer weighs less than a threshold, you say \"yes, this person should be competing in the lightweight boxing category\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d207f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def threshold_classifier(t, x):\n",
    "    return int(x <= t) #first compare x with t, and change the Boolean to an integer\n",
    "print(threshold_classifier(2,3))\n",
    "print(threshold_classifier(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd7652",
   "metadata": {},
   "source": [
    "- Step 2: Let $\\mathcal{H}$ be a collection of such $h_t$ for $t = -5, -4.5, -4, \\ldots, 4.5, 5$. Formally:\n",
    "$$\\mathcal{H} = \\{ h_t : t \\in \\{-5, -4.5, \\ldots, 4.5, 5 \\} \\}.$$ Assume we have a single instance: $C = \\{2.2\\}$, that is, we have a single point $x$ to classify. We don't know if the true label of $x$ is $y= 0 $ or $y=1$. But we would like to see, can we *at least* explain both of these cases? This will help us assess the power of our hypothesis class. Print $h_t(X)$ for all $h_t \\in \\mathcal{H}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(-5,5.1, 0.5)\n",
    "classifications = np.zeros(np.size(thresholds))\n",
    "for t in range(np.size(thresholds)):\n",
    "    classifications[t] = threshold_classifier(thresholds[t], 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2a908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold  classification\n",
      "      -5.0               0\n",
      "      -4.5               0\n",
      "      -4.0               0\n",
      "      -3.5               0\n",
      "      -3.0               0\n",
      "      -2.5               0\n",
      "      -2.0               0\n",
      "      -1.5               0\n",
      "      -1.0               0\n",
      "      -0.5               0\n",
      "       0.0               0\n",
      "       0.5               0\n",
      "       1.0               0\n",
      "       1.5               0\n",
      "       2.0               0\n",
      "       2.5               1\n",
      "       3.0               1\n",
      "       3.5               1\n",
      "       4.0               1\n",
      "       4.5               1\n",
      "       5.0               1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['threshold','classification'])\n",
    "df[\"threshold\"] = thresholds\n",
    "df[\"classification\"] = classifications.astype(int)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c38cb",
   "metadata": {},
   "source": [
    "- As we can see, we can \"achieve\" a classification of 0 or 1, by using *some* functions in $\\mathcal{H}$. This is good news, in terms of the following:\n",
    "\n",
    "`We have enough power to explain any possibe labeling of the data via the hypothesis class we constructed.`\n",
    "\n",
    "We will soon discuss whether this is a good thing, bad thing, or something that depends on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146734b",
   "metadata": {},
   "source": [
    "Question: What is $\\mathcal{H}_C$? \n",
    "\n",
    "Answer: By definition, as $\\mathcal{H}_C$ is a set, it keeps the unique collection of $h_t(2.2)$, which is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d541ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "df[\"classification\"]: This is indexing or selecting the column named \"classification\" from the DataFrame df. \n",
    "The result is a Pandas Series, which is a one-dimensional array with axis labels.\n",
    ".unique(): This is a method called on the Pandas Series that returns an array of the unique values found in that Series. \n",
    "It essentially filters out any duplicate entries, so each value in the resulting array is distinct. \n",
    "The order of the unique values in the resulting array is the order in which they appear in the original Series.\n",
    "\"\"\"\n",
    "\n",
    "H_C = df[\"classification\"].unique()\n",
    "print(H_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fe062",
   "metadata": {},
   "source": [
    "- Step 3: Let us now extend the previous example. Assume $C = \\{ 1.1, 2.2 \\}$, so we have two instances. Do not confuse this with a single instance with two \"columns\", as our domain is still restricted to $\\mathcal{X} \\subset \\mathbb{R}$. We can apply the same experiment, but for both of these instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdc63266",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(-5,5.1, 0.5)\n",
    "classifications = np.zeros((np.size(thresholds),),dtype='i,i').tolist()\n",
    "for t in range(np.size(thresholds)):\n",
    "    classifications[t] = (threshold_classifier(thresholds[t], 1.1), threshold_classifier(thresholds[t], 2.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2750ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold classification\n",
      "      -5.0         (0, 0)\n",
      "      -4.5         (0, 0)\n",
      "      -4.0         (0, 0)\n",
      "      -3.5         (0, 0)\n",
      "      -3.0         (0, 0)\n",
      "      -2.5         (0, 0)\n",
      "      -2.0         (0, 0)\n",
      "      -1.5         (0, 0)\n",
      "      -1.0         (0, 0)\n",
      "      -0.5         (0, 0)\n",
      "       0.0         (0, 0)\n",
      "       0.5         (0, 0)\n",
      "       1.0         (0, 0)\n",
      "       1.5         (1, 0)\n",
      "       2.0         (1, 0)\n",
      "       2.5         (1, 1)\n",
      "       3.0         (1, 1)\n",
      "       3.5         (1, 1)\n",
      "       4.0         (1, 1)\n",
      "       4.5         (1, 1)\n",
      "       5.0         (1, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['threshold','classification'])\n",
    "df[\"threshold\"] = thresholds\n",
    "df[\"classification\"] = classifications\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "486d3a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0) (1, 0) (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "H_C = df[\"classification\"].unique()\n",
    "print(H_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a7220",
   "metadata": {},
   "source": [
    "- We can see that $\\mathcal{H}_C$ has three functions inside, where they map $C$ to $(0,0)$, $(1,0)$, and $(1,1)$. You may notice that $(0,1)$ is missing, namely, there is not a function in $\\mathcal{H}$ such that we can correctly classify the instances $1.1, \\ 2.2$ with labels $0$ and $1$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a420b",
   "metadata": {},
   "source": [
    "- Step 4: Let us introduce a new classifier, and observe that the 'issue' we have just seen can be resolved by this classifier. Namely, let $h_{l,u}$ classify a point $x$ as $1$ if $l \\leq x \\leq u$, so that, $l$ is a lower bound threshold and $u$ is an upper bound threshold. Otherwise, let $h_{l,u}$ return $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f500408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def interval_classifier(l,u,x): #define the interval classifier\n",
    "    return int(l <= x and x <= u)\n",
    "print(interval_classifier(1,3,2))\n",
    "print(interval_classifier(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "46204d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_lower = [element for element in itertools.product(thresholds, thresholds) if element[0] <= element[1]]\n",
    "#this gives us a collection of (l,u)'s where l,u are both members of \"thresholds\" and l <= u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a457e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (0, 1), (1, 1), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "classifications = np.zeros((len(upper_lower),),dtype='i,i').tolist() #zero tuples to fill\n",
    "for t in range(len(upper_lower)): #for all l,u combinations append classifications with the result\n",
    "    classifications[t] = (interval_classifier(upper_lower[t][0],upper_lower[t][1], 1.1), \\\n",
    "                          interval_classifier(upper_lower[t][0],upper_lower[t][1], 2.2))\n",
    "unique_tuples = list(set(classifications)) #keep the unique classifications (0,0), (1,0), (0,1), (1,1)\n",
    "print(unique_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cff6241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold classification\n",
      " (-5.0, 1.5)         (1, 0)\n",
      "  (1.5, 2.5)         (0, 1)\n",
      " (-5.0, 2.5)         (1, 1)\n",
      "(-5.0, -5.0)         (0, 0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['threshold','classification'])\n",
    "df[\"classification\"] = unique_tuples #unique classifications\n",
    "unique_thresholds = np.zeros((len(unique_tuples),),dtype='i,i').tolist()\n",
    "for search in range(len(unique_tuples)):\n",
    "    unique_thresholds[search] = [upper_lower[i] for i, tupl in enumerate(classifications) if \\\n",
    "                                 tupl == unique_tuples[search]][0]\n",
    "df[\"threshold\"] = unique_thresholds #unique classifications\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef604b3",
   "metadata": {},
   "source": [
    "- We can see that if our lower bound is $-5$ and upper bound is $1.5$, then we classify the point $1.1$ with a label $1$, since it is between $-5$ and $1.5$. However, we classify $2.2$ as $0$ since it does not fall in this interval. We can see that similarly we can classify these points as $(0,1)$, $(1,1)$, and $(0,0)$. We have $2$ possible labels, and $|C| = 2$ instances, hence there are $2^{|C|}$ many possible labelings, which is equal to $4$ in this case. Hence, the interval classifier can explain every possible labels in this case where $|C| = 2$. Next, let's see if this extends to $|C| = 3$. Assume $C = \\{1.1, 2.2, 3.3\\}$ for simplicity. (Note that we can also take any possible points in $\\mathcal{X} = [-5,5]$, e.g., $C= \\{ 1,1,4.3\\}$ is also possible.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a5013412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 0), (0, 1, 0), (0, 0, 0), (1, 0, 0), (0, 0, 1), (1, 1, 1), (0, 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "classifications = np.zeros((len(upper_lower),),dtype='i,i,i').tolist() #zero tuples to fill\n",
    "for t in range(len(upper_lower)): #for all l,u combinations append classifications with the result\n",
    "    classifications[t] = (interval_classifier(upper_lower[t][0],upper_lower[t][1], 1.1),\\\n",
    "                          interval_classifier(upper_lower[t][0],upper_lower[t][1], 2.2), \\\n",
    "                          interval_classifier(upper_lower[t][0],upper_lower[t][1], 3.3))\n",
    "unique_tuples = list(set(classifications)) #keep the unique classifications (0,0), (1,0), (0,1), (1,1)\n",
    "print(unique_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "36decd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold classification\n",
      " (-5.0, 2.5)      (1, 1, 0)\n",
      "  (1.5, 2.5)      (0, 1, 0)\n",
      "(-5.0, -5.0)      (0, 0, 0)\n",
      " (-5.0, 1.5)      (1, 0, 0)\n",
      "  (2.5, 3.5)      (0, 0, 1)\n",
      " (-5.0, 3.5)      (1, 1, 1)\n",
      "  (1.5, 3.5)      (0, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['threshold','classification'])\n",
    "df[\"classification\"] = unique_tuples #unique classifications\n",
    "unique_thresholds = np.zeros((len(unique_tuples),),dtype='i,i').tolist()\n",
    "for search in range(len(unique_tuples)):\n",
    "    unique_thresholds[search] = [upper_lower[i] for i, tupl in enumerate(classifications) if \\\n",
    "                                 tupl == unique_tuples[search]][0]\n",
    "df[\"threshold\"] = unique_thresholds #unique classifications\n",
    "print(df.to_string(index=False))\n",
    "#exercise: make sure to understand this chunk of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83dfb9",
   "metadata": {},
   "source": [
    "- We can see that, we explain $7$ different labelings, so $\\mathcal{H}_C$ (recall that this means the hypothesis class $\\mathcal{H}$ restricted to the instances $C$) has a cardinality of $7$, or $|\\mathcal{H}_C| = 7$. However, we have $2^{|C|} = 2^3 = 8$, and the reason we have $|\\mathcal{H}_C| = 7$ is that we can never explain the labeling $(1,0,1)$. This is quite intuitive, since to classify the middle instance as $0$ we should make sure it is not in the specified interval, but to classify the first and last instances we should take them in an interval. Any interval that contains the first and last instances will necessarily contain the middle instance, which makes it impossible to label the three instances as $(1,0,1)$. **It is very important to notice that this result does not only hold for $C = \\{1.1, 2.2, 3.3\\}$, but any $C = \\{x_1, x_2, x_3\\}$ where $x_1, x_2, x_3 \\in \\mathcal{X}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a752b",
   "metadata": {},
   "source": [
    "#### Definition 2. $\\mathcal{H}$ shatters a finite $C \\subset \\mathcal{X}$ if $|\\mathcal{H}_C |= 2^{|C|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a7f7d",
   "metadata": {},
   "source": [
    "- This definition intuitively means that\n",
    "\n",
    "```Any of the labeling combination of the elements in C can be obtained by a function in our hypothesis class```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880d81f",
   "metadata": {},
   "source": [
    "So, we discussed that, in the case of $m=1$, the `threshold_classifier(t, x)` *shatters* $C = \\{ 2.2 \\}$. \n",
    "- Exercise: Make sure that for any $x \\in \\mathcal{X}$, `threshold_classifier(t, x)` shatters $C = \\{ x\\}$, which means any possible $C \\subset \\mathcal{X}$ with $|C| = 1$ can be shattered by the threshold classifier. \n",
    "\n",
    "Moreover, we demonstrated that `threshold_classifier(t, x)` cannot shatter $C = \\{1.1, 2.2\\}$. \n",
    "- Exercise: Show that this result generalizes for any $C \\subset \\mathcal{X}$ with $|C| = 2$. In other words, show that, there does not exist any $x_1, x_2 \\in \\mathcal{X}$ such that $|\\mathcal{H}_C |  = 2^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ba70e",
   "metadata": {},
   "source": [
    "Then, we extended our discussion to `interval_classifier(l,u,x)`. For the case of $m=2$ we showed that this classifier shatters $C = \\{1.1, 2.2 \\}$. \n",
    "- Exercise: Show that this result extends to any $C \\subset \\mathcal{X}$ as long as $|C| = 2$.\n",
    "- Exercise: Show that, if you show that if $\\mathcal{H}$ (or `interval_classifier(l,u,x)` in this context) shatters $C \\subset \\mathcal{X}$ for $|C| = 2$, then this concludes the same result for all $C \\subset \\mathcal{X}$ with $|C| = 1$.\n",
    "\n",
    "Moreover, we showed that `interval_classifier(l,u,x)` does **not** shatter $C = \\{1.1, 2.2, 3.3 \\}$. \n",
    "- Exercise: Show that this result holds for any $C \\subset \\mathcal{X}$ with $|C| = 3$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e99e71",
   "metadata": {},
   "source": [
    "#### Definition 3. The VC dimension of the hypothesis class $\\mathcal{H}$ is the maximum size of $|C|$ such that $C \\subseteq \\mathcal{X}$ can be shattered by $\\mathcal{H}$; that is, the maximum $|C|$ such that $|\\mathcal{H}_C| = 2^{|C|}$. If arbitrarily large $C$ can be shattered, we say that $\\mathcal{H}$ has an infinite VC dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bd075",
   "metadata": {},
   "source": [
    "- A typical strategy to prove the claim that $\\mathrm{VCdim}(\\mathcal{H}) = m$ is to give an example set $C \\subset \\mathcal{X}$ with $|C| = m$ that is shattered by $\\mathcal{H}$, and then to show that there is no $C \\subset \\mathcal{X}$ with $|C| \\geq m+1$ that can be shattered by $\\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300e942",
   "metadata": {},
   "source": [
    "- Example 1: Show that the VC dimension of `threshold_classifier(t,x)` is $2$\n",
    "- Example 2: Show that the VC dimension of `interval_classifier(l,u,x)` is $3$\n",
    "- Example 3 (new): Discuss that the VC dimension of $\\mathcal{H} = \\{h_{(a_1,a_2,b_1,b_2)}: a_1 \\leq a_2 \\text{ and }  b_1 \\leq b_2\\}$ is equal to $4$ where $h_{(a_1, a_2, b_1, b_2)}$ classifies a point as $1$ if the input $x = [x_1, x_2]$ is in the rectangle: $\\{x \\ : \\ a_1 \\leq x_1 \\leq a_2 \\text{ and }  x_1 \\leq x_2\\leq  b_2 \\}$. Recall that here we have $\\mathcal{X} \\subset \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118c2d0",
   "metadata": {},
   "source": [
    "- Question: Assume $\\mathcal{H}$ shatters a set $C$ of size $|C| = 20$. However, we see $10$ points of $C$ as a training set. We find a function from $\\mathcal{H}$ by 'learning' the subset of $C$ (that we see as a training set) with respect to the true labels. Since $10 \\leq 20$, and since we can shatter $|C| = 20$, then we can definitely find a function in $\\mathcal{H}$ that perfectly fits the training set. How confident are you about the performance of this function that was fit to the training set, on the remaining $10$ points? *(Philosophical hint: If someone can explain every phenomenon, his explanations are worthless.)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
