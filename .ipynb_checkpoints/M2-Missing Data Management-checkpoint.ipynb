{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127709d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import linregress\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc5477",
   "metadata": {},
   "source": [
    "## Missing Data Management and using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcd733",
   "metadata": {},
   "source": [
    "### Step 1: Understanding how we can end up with NaNs\n",
    "As a first step, let us initiate a dataframe with two columns $X_1$ and $X_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfedabab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [X1, X2]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['X1', 'X2'], dtype=float)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203c595",
   "metadata": {},
   "source": [
    "The dataframe is initialized, however, there is no row there. Let us create a new row whose $X_1$ value is equal to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb2c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'X1':1}\n",
    "\n",
    "# append this row to the dataframe\n",
    "# Note: append method in the latest versions of pandas has been made private (df._append) \n",
    "# df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "\n",
    "new_row_df = pd.DataFrame(new_row, index=[0])\n",
    "\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028db174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1  X2\n",
       "0  1.0 NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72fefb3",
   "metadata": {},
   "source": [
    "As we see, the $X_2$ value is NaN (Not a Number) which is traditionally used to model missing data. This approach is useful as otherwise we would not be able to add a row (i.e., if we require all the information to be complete, then the row above will not be appended)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1172ca",
   "metadata": {},
   "source": [
    "We can similarly assign a name to a new row. For example, let's add the same row again and name it `Alice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580402f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1  X2\n",
       "0      1.0 NaN\n",
       "Alice  1.0 NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"Alice\"] = new_row\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6d3d1",
   "metadata": {},
   "source": [
    "We can change the $X_2$ value of Alice if it is not NaN. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288f28ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2\n",
       "0      1.0  NaN\n",
       "Alice  1.0  5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"Alice\"]['X2'] = 5\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f076e",
   "metadata": {},
   "source": [
    "If we want to change the name of the first row, we can apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfcb694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2\n",
       "Bob    1.0  NaN\n",
       "Alice  1.0  5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(index={0:'Bob'},inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784a2db",
   "metadata": {},
   "source": [
    "Let us add one more row, this time with missing $X_1$. Note that the Numpy comment `np.nan` creates NaN automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8146e678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2\n",
       "Bob      1.0  NaN\n",
       "Alice    1.0  5.0\n",
       "Charlie  NaN -1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Charlie'] = [np.nan, -1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9666703",
   "metadata": {},
   "source": [
    "### Step 2: Operations on NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82eb55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1.0 and nan values\n"
     ]
    }
   ],
   "source": [
    "na_one, na_two = df.loc[\"Bob\"] #Take Bob rows\n",
    "print(\"We have\", na_one, \"and\", na_two, \"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48f1c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 1.0 and nan gives nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of\", na_one, \"and\", na_two, \"gives\", na_one + na_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28a4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication of 1.0 and nan gives nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Multiplication of\", na_one, \"and\", na_two, \"gives\", na_one * na_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b79e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of 1.0 and nan gives False\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of\", na_one, \"and\", na_two, \"gives\", na_one == na_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510d1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of nan and nan gives False that is, NaN is not even equal to itself\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of\", na_two, \"and\", na_two, \"gives\", na_two == na_two, \"that is, NaN is not even equal to itself\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ee8a6",
   "metadata": {},
   "source": [
    "We usually ask if a value is nan as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc406aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(na_two) #use numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92110263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.isnan(na_two) #use math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "549d5cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(na_two) #use pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde72d1d",
   "metadata": {},
   "source": [
    "Moreover, oficially NaN is stored as a floating number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14f8b1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(na_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b869a5",
   "metadata": {},
   "source": [
    "So if we compare the types of NaN and a number, you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ade58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(na_one) == type(na_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473383ee",
   "metadata": {},
   "source": [
    "### Step 3: Using Pandas to work with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a24bf0",
   "metadata": {},
   "source": [
    "The following drops all the rows of `df` where at least one of the values is missing, and creates a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b58be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2\n",
       "Alice  1.0  5.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9a627",
   "metadata": {},
   "source": [
    "Or, we can drop all the rows where $X_1$ value is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac935dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2\n",
       "Bob    1.0  NaN\n",
       "Alice  1.0  5.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna(subset = [\"X1\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f62bc4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2\n",
       "Alice    1.0  5.0\n",
       "Charlie  NaN -1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna(subset = [\"X2\"]) #similar for X2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd57a3",
   "metadata": {},
   "source": [
    "Add a new column based on $X_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "814ddf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2    X3\n",
       "Bob      1.0  NaN   NaN\n",
       "Alice    1.0  5.0  10.0\n",
       "Charlie  NaN -1.0  -2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"X3\"]  = df[\"X2\"]*2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f77448",
   "metadata": {},
   "source": [
    "Or, alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c83a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2    X3\n",
       "Bob      1.0  NaN   NaN\n",
       "Alice    1.0  5.0  10.0\n",
       "Charlie  NaN -1.0  -2.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"X3\"] = df.apply(lambda row: row[\"X2\"]*2, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00caab",
   "metadata": {},
   "source": [
    "If we want special treatment to NaN values, for example, if we want to initalize $X_3$ value as $0$ if $X_2$ is NaN, we can apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eda5236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1   X2    X3\n",
       "Bob      1.0  NaN   0.0\n",
       "Alice    1.0  5.0  10.0\n",
       "Charlie  NaN -1.0  -2.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"X3\"] = df.apply(lambda row: row[\"X2\"]*2 if ~np.isnan(row[\"X2\"]) else 0, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb71ca0",
   "metadata": {},
   "source": [
    "### Step 4: Exercise from the course\n",
    "Consider a database where each record has $100$ fields. Assume further that for each record, each of the $100$ fields has a $1$ per cent chance of being empty, i.e. its value is missing.\n",
    "\n",
    "If we were to remove all records with one or more empty fields, how many records would we remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b19e083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   90   91   92  \\\n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9995  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9996  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9997  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "       93   94   95   96   97   98   99  \n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "9995  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9996  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9997  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step i) Generate a matrix of rowx * 100 columns\n",
    "nr_rows = 10000 #let's say we have this many rows\n",
    "data_to_use = np.ones(nr_rows*100) #generate all-ones; numpy.ones(shape, dtype=None, order='C', *, like=None)[source] Return a new array of given shape and type, filled with ones.\n",
    "\n",
    "df_exercise = pd.DataFrame(data_to_use.reshape(nr_rows, 100)) #reshape the data so that we have rows * 100\n",
    "df_exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cbcb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step ii) Generate indices of missing values\n",
    "missing_or_not = bernoulli.rvs((1/100), size=nr_rows*100) #keeps whether or not each element of df_exercise is missing\n",
    "missing_or_not = missing_or_not.reshape(nr_rows, 100) #reshape so that index of missing values correspond to df_exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ae9bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows, missing_cols = np.where(missing_or_not == 1) #indices of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d153ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exercise.values[missing_rows, missing_cols] = np.nan #make the values missing for those indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1b0140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   90   91   92  \\\n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9995  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9996  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9997  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "       93   94   95   96   97   98   99  \n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     NaN  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "9995  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9996  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9997  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e88c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 10181 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"In total, there are\" ,np.sum(df_exercise.isnull().sum()),\"missing values\")\n",
    "#It should match `np.size(missing_rows)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c44b7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how many rows have at least one NaN\n",
    "df_missing = df_exercise.isnull().any(axis=1) #each tow has True if at least one element is nan, False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72dc6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6455 rows with at least one missing data\n",
      "So if we drop rows with missing values, we lose 0.6455 fraction of the whole data\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", np.sum(df_missing), \"rows with at least one missing data\")\n",
    "print(\"So if we drop rows with missing values, we lose\", np.sum(df_missing)/nr_rows, \"fraction of the whole data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cebda77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In other words, the following has 3545 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3545 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   90   91   92  \\\n",
       "5     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "10    1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "12    1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "14    1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "15    1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9978  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9980  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9992  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "\n",
       "       93   94   95   96   97   98   99  \n",
       "5     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "10    1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "12    1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "14    1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "15    1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "9978  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9980  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9992  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9998  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "9999  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[3545 rows x 100 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"In other words, the following has\", nr_rows - np.sum(df_missing) ,\"rows\")\n",
    "df_exercise.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cedccb",
   "metadata": {},
   "source": [
    "Of course, what we have just observed can be derived mathematically. Namely, we are interested in the probability of a single row to have no NaNs. Let $E$ be the event where all the $100$ variables are not-NaN for an arbitrary row. We then have\n",
    "\\begin{align*}\n",
    "\\mathbb{P}[E] = \\prod_{i=1}^{100} \\mathbb{P}[\\text{i-th variable is not NaN}] & = \\prod_{i=1}^{100} (1 - 1/100) \\\\\n",
    "& = \\left(\\dfrac{99}{100}\\right)^{100} = (0.99)^{100}.\n",
    "\\end{align*}\n",
    "Notice that the first equality holds as each variable has a 1 per cent probability of being NaN *independently*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "075242e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.366"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_E = 0.99 ** 100\n",
    "np.round(prob_E,3) #round to three decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73db7fc",
   "metadata": {},
   "source": [
    "Since we have `nr_rows` rows in the experiment above, we except to have $0.99 *$ `nr_rows` many rows after we drop the rows with at least one NaN values. Let's see if this is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cf9abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect to have 3660 rows that are not dropped, and our experiment ended with 3545 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"We expect to have\", round(nr_rows * prob_E), \"rows that are not dropped, and our experiment ended with\", nr_rows - np.sum(df_missing), \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35413d5e",
   "metadata": {},
   "source": [
    "Although our expectation and the result of experiment are close to each other, they are not the same number. This is due to random sampling. We will see in the upcoming modules that if we increase the number of rows in this experiment, then the number of rows that are not dropped in the experiment will be equal to $(0.99)^{100}$ as we derived."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6b926",
   "metadata": {},
   "source": [
    "### Step 5: Applications on real-life data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf3adc",
   "metadata": {},
   "source": [
    "Let us work on the following problem.\n",
    "\n",
    "Dataset: https://www.statlearning.com/s/College.csv\n",
    "Variables are explained at [this link](https://lse-me314.github.io/solutions/ME314_assignment1_solution.html).\n",
    "\n",
    "We modify the dataset and provide you with a version which has missing values. It is named as \"college_missing.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d999eb",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "### Missing values\n",
    "#### a) Read the dataset by using Pandas and have a first look\n",
    "#### b) Find out which values are missing\n",
    "#### c) Replace the missing values with the mean for the feature\n",
    "#### d) Figure out what is wrong with doing (c)\n",
    "#### e) Replace the missing values using a linear model to estimate the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63d59e",
   "metadata": {},
   "source": [
    "# Solutions:\n",
    "#### a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ab7c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_college = pd.read_csv(\"college_missing.csv\",index_col=0) #read the data\n",
    "df_college = pd.read_csv(\"./W2/college.csv\",index_col=0) #read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a521aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "Abilene Christian University     Yes  1660    1232     721         23   \n",
       "Adelphi University               Yes  2186    1924     512         16   \n",
       "Adrian College                   Yes  1428    1097     336         22   \n",
       "Agnes Scott College              Yes   417     349     137         60   \n",
       "Alaska Pacific University        Yes   193     146      55         16   \n",
       "\n",
       "                              Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
       "Abilene Christian University         52         2885          537      7440   \n",
       "Adelphi University                   29         2683         1227     12280   \n",
       "Adrian College                       50         1036           99     11250   \n",
       "Agnes Scott College                  89          510           63     12960   \n",
       "Alaska Pacific University            44          249          869      7560   \n",
       "\n",
       "                              Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "Abilene Christian University        3300    450      2200   70        78   \n",
       "Adelphi University                  6450    750      1500   29        30   \n",
       "Adrian College                      3750    400      1165   53        66   \n",
       "Agnes Scott College                 5450    450       875   92        97   \n",
       "Alaska Pacific University           4120    800      1500   76        72   \n",
       "\n",
       "                              S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "Abilene Christian University       18.1           12    7041         60  \n",
       "Adelphi University                 12.2           16   10527         56  \n",
       "Adrian College                     12.9           30    8735         54  \n",
       "Agnes Scott College                 7.7           37   19016         59  \n",
       "Alaska Pacific University          11.9            2   10922         15  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college.head() #inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af66e3",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2e6dbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private        0\n",
       "Apps           0\n",
       "Accept         0\n",
       "Enroll         0\n",
       "Top10perc      0\n",
       "Top25perc      0\n",
       "F.Undergrad    0\n",
       "P.Undergrad    0\n",
       "Outstate       0\n",
       "Room.Board     0\n",
       "Books          0\n",
       "Personal       0\n",
       "PhD            0\n",
       "Terminal       0\n",
       "S.F.Ratio      0\n",
       "perc.alumni    0\n",
       "Expend         0\n",
       "Grad.Rate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college.isna().sum() #how many missing values under each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cb70aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_apps = df_college[df_college['Apps'].isnull()].index.tolist() #missing applications (indexes)\n",
    "missing_accepts = df_college[df_college['Accept'].isnull()].index.tolist() #missing accepts (indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf645387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_apps #names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc2ba5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_accepts #names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1dad8",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02f6dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_apps = df_college[\"Apps\"].mean() #compute mean of apps -- pandas automatically excludes NaNs!\n",
    "mean_of_accepts = df_college[\"Accept\"].mean() #compute mean of accepts -- pandas automatically excludes NaNs!\n",
    "df_college_v1 = df_college.copy()#copy the dataframe as we will fill the missing data (we still want to keep original, so we copy it to a new one) \n",
    "df_college_v1.loc[df_college_v1[\"Apps\"].isnull(), 'Apps']  = mean_of_apps #whenever there is missing data on \"apps\" change it with the mean\n",
    "df_college_v1.loc[df_college_v1[\"Accept\"].isnull(), 'Accept']  = mean_of_accepts #same for accepts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6a9a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186.0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worcester State College</th>\n",
       "      <td>No</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier University of Louisiana</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yale University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>York College of Pennsylvania</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Private     Apps  Accept  Enroll  Top10perc  \\\n",
       "Abilene Christian University       Yes   1660.0  1232.0     721         23   \n",
       "Adelphi University                 Yes   2186.0  1924.0     512         16   \n",
       "Adrian College                     Yes   1428.0  1097.0     336         22   \n",
       "Agnes Scott College                Yes    417.0   349.0     137         60   \n",
       "Alaska Pacific University          Yes    193.0   146.0      55         16   \n",
       "...                                ...      ...     ...     ...        ...   \n",
       "Worcester State College             No   2197.0  1515.0     543          4   \n",
       "Xavier University                  Yes   1959.0  1805.0     695         24   \n",
       "Xavier University of Louisiana     Yes   2097.0  1915.0     695         34   \n",
       "Yale University                    Yes  10705.0  2453.0    1317         95   \n",
       "York College of Pennsylvania       Yes   2989.0  1855.0     691         28   \n",
       "\n",
       "                                Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
       "Abilene Christian University           52         2885          537      7440   \n",
       "Adelphi University                     29         2683         1227     12280   \n",
       "Adrian College                         50         1036           99     11250   \n",
       "Agnes Scott College                    89          510           63     12960   \n",
       "Alaska Pacific University              44          249          869      7560   \n",
       "...                                   ...          ...          ...       ...   \n",
       "Worcester State College                26         3089         2029      6797   \n",
       "Xavier University                      47         2849         1107     11520   \n",
       "Xavier University of Louisiana         61         2793          166      6900   \n",
       "Yale University                        99         5217           83     19840   \n",
       "York College of Pennsylvania           63         2988         1726      4990   \n",
       "\n",
       "                                Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "Abilene Christian University          3300    450      2200   70        78   \n",
       "Adelphi University                    6450    750      1500   29        30   \n",
       "Adrian College                        3750    400      1165   53        66   \n",
       "Agnes Scott College                   5450    450       875   92        97   \n",
       "Alaska Pacific University             4120    800      1500   76        72   \n",
       "...                                    ...    ...       ...  ...       ...   \n",
       "Worcester State College               3900    500      1200   60        60   \n",
       "Xavier University                     4960    600      1250   73        75   \n",
       "Xavier University of Louisiana        4200    617       781   67        75   \n",
       "Yale University                       6510    630      2115   96        96   \n",
       "York College of Pennsylvania          3560    500      1250   75        75   \n",
       "\n",
       "                                S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "Abilene Christian University         18.1           12    7041         60  \n",
       "Adelphi University                   12.2           16   10527         56  \n",
       "Adrian College                       12.9           30    8735         54  \n",
       "Agnes Scott College                   7.7           37   19016         59  \n",
       "Alaska Pacific University            11.9            2   10922         15  \n",
       "...                                   ...          ...     ...        ...  \n",
       "Worcester State College              21.0           14    4469         40  \n",
       "Xavier University                    13.3           31    9189         83  \n",
       "Xavier University of Louisiana       14.4           20    8323         49  \n",
       "Yale University                       5.8           49   40386         99  \n",
       "York College of Pennsylvania         18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74998869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private        0\n",
       "Apps           0\n",
       "Accept         0\n",
       "Enroll         0\n",
       "Top10perc      0\n",
       "Top25perc      0\n",
       "F.Undergrad    0\n",
       "P.Undergrad    0\n",
       "Outstate       0\n",
       "Room.Board     0\n",
       "Books          0\n",
       "Personal       0\n",
       "PhD            0\n",
       "Terminal       0\n",
       "S.F.Ratio      0\n",
       "perc.alumni    0\n",
       "Expend         0\n",
       "Grad.Rate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v1.isna().sum() #all fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62f472",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd56a843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Apps, Accept]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v1.loc[missing_apps, [\"Apps\", \"Accept\"]] #we accepted more than the applications in some unis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f7f512b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Apps, Accept]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v1.loc[missing_accepts, [\"Apps\", \"Accept\"]] #we accepted more than the applications in some unis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966cfe8",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c06ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_college_v2 = df_college.copy() #copy to a new one (we will use lin-reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42a2e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_college_v2_complete = df_college_v2.dropna() #drop nans as we want to fit a linear model \n",
    "df_college_v2_complete = df_college_v2_complete[[\"Apps\", \"Accept\"]] #take only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6ec02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Apps  Accept\n",
       "Abilene Christian University  1660    1232\n",
       "Adelphi University            2186    1924\n",
       "Adrian College                1428    1097\n",
       "Agnes Scott College            417     349\n",
       "Alaska Pacific University      193     146"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v2_complete.head() #have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5db24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_predict_accept, intercept_predict_accept, r_value, p_value, std_err = \\\n",
    "    linregress(df_college_v2_complete[\"Apps\"],df_college_v2_complete[\"Accept\"]) #use scipy to fit a linear regression\n",
    "#this model explains the \"accepts\" by using \"Apps\" as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "136cf962",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_predict_apps, intercept_predict_apps, r_value, p_value, std_err = \\\n",
    "    linregress(df_college_v2_complete[\"Accept\"],df_college_v2_complete[\"Apps\"]) #use scipy\n",
    "#this model explains the \"Apps\" by using \"accepts\" as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "447022b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fill missing values now based on the linear model\n",
    "df_college_v2[\"Accept\"] = df_college_v2.apply(lambda row:\\\n",
    "    slope_predict_accept*row[\"Apps\"] + intercept_predict_accept if math.isnan(row[\"Accept\"]) else row[\"Accept\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f054a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fill missing values now based on the linear model\n",
    "df_college_v2[\"Apps\"] = df_college_v2.apply(lambda row:\\\n",
    "    slope_predict_apps*row[\"Accept\"] + intercept_predict_apps if math.isnan(row[\"Apps\"]) else row[\"Apps\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a50a22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worcester State College</th>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier University of Louisiana</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yale University</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>York College of Pennsylvania</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Private   Apps  Accept  Enroll  Top10perc  \\\n",
       "Abilene Christian University       Yes   1660    1232     721         23   \n",
       "Adelphi University                 Yes   2186    1924     512         16   \n",
       "Adrian College                     Yes   1428    1097     336         22   \n",
       "Agnes Scott College                Yes    417     349     137         60   \n",
       "Alaska Pacific University          Yes    193     146      55         16   \n",
       "...                                ...    ...     ...     ...        ...   \n",
       "Worcester State College             No   2197    1515     543          4   \n",
       "Xavier University                  Yes   1959    1805     695         24   \n",
       "Xavier University of Louisiana     Yes   2097    1915     695         34   \n",
       "Yale University                    Yes  10705    2453    1317         95   \n",
       "York College of Pennsylvania       Yes   2989    1855     691         28   \n",
       "\n",
       "                                Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
       "Abilene Christian University           52         2885          537      7440   \n",
       "Adelphi University                     29         2683         1227     12280   \n",
       "Adrian College                         50         1036           99     11250   \n",
       "Agnes Scott College                    89          510           63     12960   \n",
       "Alaska Pacific University              44          249          869      7560   \n",
       "...                                   ...          ...          ...       ...   \n",
       "Worcester State College                26         3089         2029      6797   \n",
       "Xavier University                      47         2849         1107     11520   \n",
       "Xavier University of Louisiana         61         2793          166      6900   \n",
       "Yale University                        99         5217           83     19840   \n",
       "York College of Pennsylvania           63         2988         1726      4990   \n",
       "\n",
       "                                Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "Abilene Christian University          3300    450      2200   70        78   \n",
       "Adelphi University                    6450    750      1500   29        30   \n",
       "Adrian College                        3750    400      1165   53        66   \n",
       "Agnes Scott College                   5450    450       875   92        97   \n",
       "Alaska Pacific University             4120    800      1500   76        72   \n",
       "...                                    ...    ...       ...  ...       ...   \n",
       "Worcester State College               3900    500      1200   60        60   \n",
       "Xavier University                     4960    600      1250   73        75   \n",
       "Xavier University of Louisiana        4200    617       781   67        75   \n",
       "Yale University                       6510    630      2115   96        96   \n",
       "York College of Pennsylvania          3560    500      1250   75        75   \n",
       "\n",
       "                                S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "Abilene Christian University         18.1           12    7041         60  \n",
       "Adelphi University                   12.2           16   10527         56  \n",
       "Adrian College                       12.9           30    8735         54  \n",
       "Agnes Scott College                   7.7           37   19016         59  \n",
       "Alaska Pacific University            11.9            2   10922         15  \n",
       "...                                   ...          ...     ...        ...  \n",
       "Worcester State College              21.0           14    4469         40  \n",
       "Xavier University                    13.3           31    9189         83  \n",
       "Xavier University of Louisiana       14.4           20    8323         49  \n",
       "Yale University                       5.8           49   40386         99  \n",
       "York College of Pennsylvania         18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a158f9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Apps, Accept]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v2.loc[missing_apps, [\"Apps\", \"Accept\"]] #we accepted more than the applications in some unis!\n",
    "# all stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33db5f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Apps, Accept]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college_v2.loc[missing_accepts, [\"Apps\", \"Accept\"]] #we accepted more than the applications in some unis!\n",
    "# only firsty two have Accept > Apps but better than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd593da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
